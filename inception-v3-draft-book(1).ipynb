{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt # graphs\n\nimport torch # tensors\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ncheckpoints = '/kaggle/working/checkpoints/'\nif not os.path.exists(checkpoints):\n    os.makedirs(checkpoints)\n# !pip install timm\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-04T19:58:38.634747Z","iopub.execute_input":"2023-06-04T19:58:38.635523Z","iopub.status.idle":"2023-06-04T19:58:40.498543Z","shell.execute_reply.started":"2023-06-04T19:58:38.635475Z","shell.execute_reply":"2023-06-04T19:58:40.497495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_bird_data(augmentation=0):\n    transform_train = transforms.Compose([\n        transforms.Resize(299),\n        transforms.RandomCrop(299, padding=8, padding_mode='edge'), # Take 299x299 random crops\n        transforms.RandomHorizontalFlip(),    # 50% of time flip image along y-axis\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    transform_test = transforms.Compose([\n        transforms.Resize(299),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    if augmentation == -1:\n        transform_train = transorm_test\n    \n    trainset = torchvision.datasets.ImageFolder(root='/kaggle/input/birds23sp/birds/train', transform=transform_train)\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n#     # split our training data into a training set and a validation set, so I can tweak lr if needed and know model acc\n#     train_subset, val_subset = torch.utils.data.random_split(\n#         trainset, [.9, .1], generator=torch.Generator().manual_seed(455))\n#     # valloader will be input processed like the training set, that should be fine\n#     trainloader = torch.utils.data.DataLoader(train_subset, batch_size=128, shuffle=True, num_workers=2)\n#     valloader = torch.utils.data.DataLoader(val_subset, batch_size=128, shuffle=True, num_workers=2\n#     , 'val': valloader \n    \n    testset = torchvision.datasets.ImageFolder(root='/kaggle/input/birds23sp/birds/test', transform=transform_test)\n    testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n    classes = open(\"/kaggle/input/birds23sp/birds/names.txt\").read().strip().split(\"\\n\")\n    class_to_idx = trainset.class_to_idx\n    idx_to_class = {int(v): int(k) for k, v in class_to_idx.items()}\n    idx_to_name = {k: classes[v] for k,v in idx_to_class.items()}\n    return {'train': trainloader, 'test': testloader, 'to_class': idx_to_class, 'to_name':idx_to_name}\n\ndata = get_bird_data()","metadata":{"execution":{"iopub.status.busy":"2023-06-04T19:58:40.500858Z","iopub.execute_input":"2023-06-04T19:58:40.501851Z","iopub.status.idle":"2023-06-04T19:58:44.807290Z","shell.execute_reply.started":"2023-06-04T19:58:40.501813Z","shell.execute_reply":"2023-06-04T19:58:44.806325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EnsembleModel(nn.Module):   \n    def __init__(self, modelA, modelB):\n        super().__init__()\n        self.modelA = modelA\n        self.modelB = modelB\n        self.classifier = nn.Linear(555*2, 555)\n        \n    def forward(self, x):\n        x1 = self.modelA(x)[0]\n        x2 = self.modelB(x)\n        x = torch.cat((x1, x2), dim=1)\n        out = self.classifier(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-06-04T19:58:44.808920Z","iopub.execute_input":"2023-06-04T19:58:44.809734Z","iopub.status.idle":"2023-06-04T19:58:44.817224Z","shell.execute_reply.started":"2023-06-04T19:58:44.809699Z","shell.execute_reply":"2023-06-04T19:58:44.816336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(net, dataloader, epochs=1, start_epoch=0, lr=0.01, momentum=0.9, decay=0.0005, \n          verbose=1, print_every=10, state=None, schedule={}, checkpoint_path=None):\n    net.to(device)\n    net.train()\n    losses = []\n    vallosses = []\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n\n    # Load previous training state\n    if state:\n        net.load_state_dict(state['net'])\n        optimizer.load_state_dict(state['optimizer'])\n        start_epoch = state['epoch']\n        losses = state['losses']\n\n    # Fast forward lr schedule through already trained epochs\n    for epoch in range(start_epoch):\n        if epoch in schedule:\n            print (\"Learning rate: %f\"% schedule[epoch])\n            for g in optimizer.param_groups:\n                g['lr'] = schedule[epoch]\n    min_ep_loss = 100000    \n    min_ep = 0\n    for epoch in range(start_epoch, epochs):\n        ep_loss = 0\n        sum_loss = 0.0\n\n        # Update learning rate when scheduled\n        if epoch in schedule:\n            print (\"Learning rate: %f\"% schedule[epoch])\n            for g in optimizer.param_groups:\n                g['lr'] = schedule[epoch]\n\n        for i, batch in enumerate(dataloader, 0):\n            inputs, labels = batch[0].to(device), batch[1].to(device)\n\n            optimizer.zero_grad()\n\n            outputs = net(inputs)\n            # fetches the raw output, not the auxilory tensor. Inception net specific (on the [0])\n            loss = criterion(outputs[0], labels)\n            loss.backward()  # autograd magic, computes all the partial derivatives\n            optimizer.step() # takes a step in gradient direction\n\n            losses.append(loss.item())\n            sum_loss += loss.item()\n\n            if i % print_every == print_every-1:    # print every 10 mini-batches\n                if verbose:\n                  print('[%d, %5d] loss: %.3f' % (epoch, i + 1, sum_loss / print_every))\n                ep_loss += sum_loss \n                sum_loss = 0.0\n        if checkpoint_path:\n            state = {'epoch': epoch+1, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'losses': losses}\n            torch.save(state, checkpoint_path + 'checkpoint-%d.pkl'%(epoch+1))\n        if ep_loss < min_ep_loss:\n            min_ep_loss = ep_loss\n            min_ep = epoch+1\n    print(\"Min loss at epoch (1 indexed): \" + str(min_ep) + \" with loss: \" + str(min_ep_loss))\n    return losses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# actual training of the model\ninceptionnet = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\ninceptionnet.fc = nn.Sequential(\n    nn.Linear(2048, 1000),\n    nn.ReLU(),\n    nn.Linear(1000, 555),\n)\n# MEALnet = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50', pretrained=True)\n# MEALnet.fc = nn.Linear(2048, 555)\n# ensemble = EnsembleModel(inceptionnet, MEALnet) -- MEAL was too much RAM\n\n\nlosses = train(inceptionnet, data['train'], epochs=7, schedule={0:.01, 3:.001, 6:.0001}, lr=.01, print_every=50,\n               checkpoint_path=checkpoints)","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-06-04T21:23:02.012082Z","iopub.execute_input":"2023-06-04T21:23:02.012464Z","iopub.status.idle":"2023-06-04T21:27:04.874288Z","shell.execute_reply.started":"2023-06-04T21:23:02.012431Z","shell.execute_reply":"2023-06-04T21:27:04.872750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inceptionnet = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\ninceptionnet.fc = nn.Sequential(\n    nn.Linear(2048, 1000),\n    nn.ReLU(),\n    nn.Linear(1000, 555),\n)\n# MEALnet = torch.hub.load('szq0214/MEAL-V2','meal_v2', 'mealv2_resnest50_cutmix', pretrained=True)\n# ensemble = EnsembleModel(inceptionnet, MEALnet)\ndata = get_bird_data(1)\nstate = torch.load(checkpoints + 'checkpoint-7.pkl')\n\nlosses = train(inceptionnet, data['train'], epochs=15, schedule={0:.01, 3:.001, 6:.0001, 10:.00002}, lr=.01, print_every=50,\n               checkpoint_path=checkpoints, state = state)","metadata":{"execution":{"iopub.status.busy":"2023-06-04T19:58:49.326321Z","iopub.execute_input":"2023-06-04T19:58:49.326692Z","iopub.status.idle":"2023-06-04T21:12:24.652164Z","shell.execute_reply.started":"2023-06-04T19:58:49.326661Z","shell.execute_reply":"2023-06-04T21:12:24.647984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(net, dataloader, ofname):\n    out = open(ofname, 'w')\n    out.write(\"path,class\\n\")\n    net.to(device)\n    net.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(dataloader, 0):\n            if i%100 == 0:\n                print(i)\n            images, labels = images.to(device), labels.to(device)\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            fname, _ = dataloader.dataset.samples[i]\n            out.write(\"test/{},{}\\n\".format(fname.split('/')[-1], data['to_class'][predicted.item()]))\n    out.close()\n    \n# accuracy is ultra slow for some reason, so unreasonable to run,, unfortunately.\ndef accuracy(net, dataloader):\n    net.to(device)\n    net.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(dataloader, 0):\n            if i%100 == 0:\n                print(i)\n            images, labels = images.to(device), labels.to(device)\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            corr_it = (predicted == labels).float().sum()\n            correct += corr_it.item()\n            total += len(labels)\n    acc = correct/total * 100\n    return acc","metadata":{"execution":{"iopub.status.busy":"2023-06-04T21:14:35.180165Z","iopub.execute_input":"2023-06-04T21:14:35.180573Z","iopub.status.idle":"2023-06-04T21:14:35.193101Z","shell.execute_reply.started":"2023-06-04T21:14:35.180543Z","shell.execute_reply":"2023-06-04T21:14:35.192006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluation section\ndata = get_bird_data(-1)\nprint(accuracy(inceptionnet, data['train']))\npredict(inceptionnet, data['test'], \"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-06-04T21:14:37.599740Z","iopub.execute_input":"2023-06-04T21:14:37.600455Z","iopub.status.idle":"2023-06-04T21:22:46.869276Z","shell.execute_reply.started":"2023-06-04T21:14:37.600419Z","shell.execute_reply":"2023-06-04T21:22:46.867760Z"},"trusted":true},"execution_count":null,"outputs":[]}]}